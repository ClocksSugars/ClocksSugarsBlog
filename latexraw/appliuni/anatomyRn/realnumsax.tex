\documentclass[11pt]{article}
    \title{\textbf{Default Doc}}
    \date{\the\day/\the\month/\the\year}

\input{../pdf.tex}
\input{../webmacros.tex}
\input{../amsthmstuff.tex}




\begin{document}

As I have said in the previous chapter, real analysis usually proves a novel difficulty for the newly interested mathematician, since they are generally practiced on the intuitions of physics dressed up for the purposes of analytic geometry. This can make foundational statements about the real numbers appear tautological since it is unclear how one applies \squote{strict rigor} when we are unsure what rules we have and which we do not, thus returning us to the potholes of a more naive intuition's reasoning.

My sense about this is that it is most easily remedied by simply working within the rules proper from the very beginning. One discovers on meeting real analysis, for the first time, that they did not truly know what a real number really was. Natural numbers, integers, rational numbers, each have strict rules for where new instances come from, either by counting rules, or extending subtraction or division as necessary, but this is not so immediately true for the real numbers, not in any useful way anyway. It could equally be said inversely that real numbers are so easy to create that it is hard to understand how exhaustive (or indeed restrictive, if you have been convinced that $dx$ is a number) the reals are.

So we will continue, in some sense, our discussion from the previous chapter into this one, and describe the real numbers as a set defined with member objects that obey certain symbolic rules. In this way, a real number will be no more and no less than the totality of these rules to us than their consequences and reinterpretations.

A final note that must be said at the beginning of this chapter: it is presumed that you read the previous chapter. If you did not, either because you felt sufficiently familiar with the language of mathematics or because it somehow struck you as unapplicable, then first and foremost, my apologies. Secondly however, you will certainly need to know if you did not read or follow the previous section, that the symbol $\in$ is read as \squote{in} or \squote{is a member of}; this means $a,b\in \reals$ is to be read as \squote{$a$ and $b$ are in the set of real numbers} and thus interpretted that $a$ and $b$ are real numbers by loose analogy to a type relation. Moreover I highly recommend that you at least keep an open tab of the latter parts of \href{https://clockssugars.blog/appliuni/prelims/philofmath.html}{Nascent's Philosophy of Mathematics} and \href{https://clockssugars.blog/appliuni/prelims/maththink.html}{Rewrites and Sets}, both which contain a few lists of definitions which you should check should you encounter a word or notation you are unable to immediately understand.

\subsection{The Real Number Axioms}

There are of course multiple axiomitizations of the real numbers, but to avoid confusing you, we will use these fourteen, most of which are borrowed from other constructions. That is, the set of real numbers is a \emph{complete ordered field}, meaning that it is first an algebraic field defined with addition and multiplication, subtraction and division, and other appropriate rules; it has an ordering so every number can be compared to one another, and it is complete in a way we will discuss shortly. Short of completeness, these axioms in fact describe the rational numbers, and in fact each of those terms, completeness, orderedness, or an algebraic field, are important and relevant on their own. For our purposes, by the time we meet many of these concepts formally, we will think of them in many ways as \squote{real numbers but without} some property. 

\begin{label definition}[Real Number Axioms]{RealNumberAxioms}
Denote by $\reals$ the set which is an ordered field for which all subsets have a least upper bound. That is: \begin{itemize}
\item (Algebraic Field) $\reals$ is a set with a binary operation called addition and a binary operation called multiplication. For elements $a,b \in \reals$, we denote addition as $a + b$ and multiplication as $a b$ or sometimes $a \cdot b$, rarely $a \times b$. For any $a,b,c \in \reals$ these operations satisfy \begin{itemize}
		\item (RNFA1) addition is associative, meaning $(a+b) + c = a + (b + c)$.
		\item (RNFA2) addition is commutative, meaning $a+b = b+a$.
		\item (RNFA3) addition has an identity $z_+$, satisfying $a + z_+ = a$ and $z_+ + a = a$.
		\item (RNFA4) addition is invertible, so for all $a \in \reals$ there exists a unique $w$ such that $a + w = z_+$ leaving only the additive identity.
		\item (RNFA5) multiplication is associative, meaning $(ab)c = a(bc)$.
		\item (RNFA6) multiplication is commutative, meaning $ab = ba$.
		\item (RNFA7) multiplication has an identity $z_\times$, satisfying $a z_\times = a$ and $z_\times a = a$
		\item (RNFA8) multiplication is almost always invertible, so for any $a \in \reals \setminus \{z_+\}$, that is, any number $a$ which is not the additive identity, there exists a unique $w$ such that $a w = z_\times$ and $w a = z_\times$.
		\item (RNFA9) multiplication is \textbf{distributive}, meaning that $a(b + c) = a b + a c$.
	\end{itemize}
\item (Ordered) $\reals$ is a set with a binary relation $<$. For all $a,b,c \in \reals$ it satisfies \begin{itemize}
		\item (RNOA1) the relation forms a \emph{trichotomy}, so either $a < b$ or $a = b$ or $b < a$, but there is no fourth option and exactly one of the three is always true.
		\item (RNOA2) the relation is transitive, so if $a < b$ and $b < c$ then $a < c$.
		\item (RNOA3) translations preserve orderings, so if $a < b$ then $a + c < b + c$.
		\item (RNOA4) positive dilations preserve orderings, so if $a < b$ and $z_+ < c$ then $a c < b c$.
	\end{itemize}
\item (Completeness) For all nonempty sets $A \subset \reals$ which have an \textbf{upper bound}, that is, some number $b \in \reals$ such that $a < b$ or $a = b$ (i.e. $a \le b$) for all $a \in A$, there must exist some \textbf{least upper bound} called the \textbf{supremum}, which we write $\sup(A) \in \reals$. The least upper bound must simultaneously satisfy that $a \le \sup(A)$ for all $a \in A$, the property of an upper bound, and that for all upper bounds $b$ of $A$, it is $\sup(A) \le b$.
\end{itemize}
\end{label definition}

You may immediately deduce the way that your understanding of the real numbers maps onto this description. That is, although wrapped up in symbols, $z_+ = 0$ and $z_\times = 1$, and that the additive inverse for some $a \in \reals$ is $-a$ while the multiplicative inverse is $1/a$. However I must emphasize that notions such as these, the idea that the inverse of a number is one divided by it is a notation, and writing a negative sign in front of a number to denote its additive inverse (via $(-1) \cdot a$) is yet to be validated. Indeed, even the statement $z_+ = 0$ and $z_\times = 1$ is a choice that defines how we write the real numbers, fixing its scale by saying that the quantity $z_\times - z_+$ will be written by us as 1.

This collection of fourteen axioms combines three different things that we tend to want from a \squote{number system} that could enable us to speak on matters of geometry and algebra simultaneously. It is an \emph{algebraic field}, in the sense of a number system with addition, subtraction, multiplication, division, a zero that adds nothing, and a one that multiplies nothing. These properties are also satisfied by the complex numbers, the rational numbers, and indeed the binary field which is composed of only the elements $\{0,1\}$ where computer science is concerned. It is ordered in the way we need it to be in order to \emph{measure} things and compare those measurements on one strict axis, like the counting numbers, the integers, and the rationals; it enables us to say that one thing is greater than another or smaller or equal but never incomparable.

But then the real numbers have one other strange property which I might argue enables it to be useful in matters of geometry, which is that it is \emph{complete}. The axis created by the order axioms cannot ever be partitioned in such a way that there are two non-overlapping sets with no element between them, because \emph{there are no gaps} since $\reals$ is complete. In fact all of the axioms stated, up until the condition of completeness, describes the rational numbers which are not themselves complete. To state a collection of axioms for the reals is significantly easier than it is to construct the real numbers in any type theoretic sense precisely because of the axiom of completeness. The description I just gave, of real numbers as a real ordered set \emph{with no gaps} corresponds to the \squote{Dedekind cut} construction of the real numbers, where every number is uniquely identified by a point you can split the real number line in two at leaving a point in the middle.

While the nuances of constructing the real numbers is far beyond the scope of this section, it is valuable to understand for later that real numbers are not nearly as easily discussed or pointed at as one might think. Indeed, we will discuss later in this chapter how almost all real numbers are effectively impossible to discuss. But it is our job for the majority of this chapter, so long as we wear the hats of \squote{real analysts} that we remain uninterested in the various difficulties of that construction; the study of real numbers has many much more interesting things to tell us even with that put aside.

First, since I had promised that this chapter would explore the practical implementation of rewriting reasoning with real numbers, let us write explicitly some rules which are not written above since they are a combined consequence of the real numbers and the properties of equality. This will begin our promised elaboration of math as simply a list of rewrite rules; we are in some sense rejecting a pursuit of \emph{truth} to demonstrate the power of truth-as-process, since all we know about our real numbers is these fourteen symbolic rules.

\begin{label lemma}[Real Number Algebra Rewrite Rules]{RealNumsAlgebraRewrites}
Let $a,b,c \in \reals$ be real numbers and let $f \colon \reals \to \reals$. Then the following rewrites are conditionally valid. \begin{enumerate}
\item $a = c$ if and only if $a + b = c + b$
\item if $b \neq 0$ then $a = c$ if and only if $a b = c b$
\item if $a = c$ then $f(a) = f(c)$
\item if $f$ is injective then $f(a) = f(c)$ if and only if $a = c$
\end{enumerate}
\end{label lemma}

\begin{my proof}{mo}
Recall that equality is reflexive, %%% add reference here!!
meaning that for all symbols $x$, we have $x = x$. For part a of the lemma, this means that both $a = a$ and $a + b = a + b$. Since equality implies a rewrite rule, we can rewrite $a + b$ to $c + b$ on the right hand side, obtaining $a + b = c + b$. For the reverse direction, take $d \in \reals$ to be the additive inverse of $b$, so that $b + d = 0$. Apply the rule once more to obtain \begin{gather*}
a + b + d = c + b + d
\end{gather*}
followed by applying associativity of addition (RNFA1) to place brackets \begin{gather*}
a + (b + d) = c + (b + d)
\end{gather*} and then applying the additive inverse property (RNFA4, i.e. rewrite $b + d$ to $0$) followed by the identity property (RNFA3) to eliminate zeroes via $x + 0 = x$.
\begin{align*}
a + 0 &= c + 0 \\
a & = c
\end{align*}
Thus $a + b = c + b$ also implies $a = c$.


We can repeat this process also for multiplication, saying that $a b = a b$ by reflexivity of equality, and then rewriting $a b$ on the right hand side to $c b$. Once more, obtain the reverse direction by assigning $d$ the multiplicative inverse to $b$ satisfying $bd = 1$ and applying the rule once more \begin{align*}
a b d &= c b d \\
a (b d) &= c (b d) \\
a (1) &= c (1) \\
a &= c
\end{align*}
applying this time RNFA5, RNFA8 and then RNFA7 to repeat the steps mentioned before for multiplication instead of addition. 

Once again, we do not do this by thinking about what \emph{is true}, we do this on the basis of the rules that we have, those being reflexivity and rewrite under equality.

For part c this is even simpler, taking $f(a) = f(a)$ by reflexivity and rewriting the right hand side to $f(c)$ and obtaining $f(a) = f(c)$. In general, the reverse direction does not hold unless $f$ is injective, in which case we move to part d.

For part d, recall the definition of injectivity. A function $f$ is injective when it satisfies the rules that $f(x_1) = f(x_2)$ if and only if $x_1 = x_2$. In this case, our $x_1$ is $a$ and our $x_2 = c$, so if $f(a) = f(c)$, we notice that what we are trying to prove is the literal definition of injectivity, so we are done.

\qed
\end{my proof}

These rewrite rules will be taken as trivial from now on and exercised simply by saying \squote{we [do a thing] to both sides}. In fact if one thinks of $f(x) = x + b$ or $f(x) = x b$ then both parts a and b's forward implications were merely special cases of part c; this means as well that the rule extends to subtraction and division. In fact we never particularly used the property that $f$ was a function on real numbers either, so in fact these \emph{algebraic rewrites} remain valid on any system of numbers for which we have a valid function $f$.

A series of obvious constructions must follow, along with some less obvious ones. Given the ordering $<$, we have the dual ordering $>$ in which $a < b$ if and only if $b > a$, as well as the partial order $a\le b$ which can be treated as the proposition $a < b \vee a = b$, with its dual $\ge$. We also consider subtraction to be the operation of taking a number's additive inverse and adding it instead, likewise for division multiplying a number's multiplicative inverse. This can be stated as saying, literally, that $a - b = c$ is \emph{defined} as the solution $c$ to $c + b = a$, and $a/b = c$ is defined as the solution $c$ to $b c = a$. It is preferable at this stage however, since these definitions correspond to unique solutions, to simply consider these inverses as functions which we will do shortly.

Let us show some well known facts in order to explore how we arrive at common intuitions from these pure symbolic rules. 

\begin{label proposition}{RealNumInverses}
Let $a,b,c \in \reals$. For the purposes of notation, let $I_+\colon \reals \to \reals$ be a function that maps each real number to its unique additive inverse, i.e. $a + I(a) = z_+ = 0$ for all $a \in \reals$. Likewise, define $I_\times \colon \reals \setminus \{0\} \to \reals \setminus \{0\}$ be the multiplicative inverse which sends each number that is not zero to its unique multiplicative inverse, so that $a \cdot I(a) = z_\times = 1$. Given our above description of subtraction and division, this means that we read $x - y$ as $x + I_+(y)$ and $x/y$ as $ x \cdot I_\times(y)$ and take these as rewrite rules. Then the following hold.\begin{enumerate}
\item $I_+(I_+(a)) = a$ and $I_\times(I_\times(a)) = a$.
\item If $a c = 1$ then $c = 1/a$ which we also write $c = a^\inv$. In effect, $I_\times(a) = 1/a$.
\item Any number multiplied by zero is zero, i.e. $z_+ \cdot a = z_+$.
\item If $a+c=0$ then $c = (-1)a$, or rather, in general $I_+(a) = I_+ (z_\times) a$. In effect, $I_+(a) = -a$ where $-a$ is shorthand for $(-1)a$.
\end{enumerate}
\end{label proposition}

\begin{my proof}{mo}
First let us show part a. This is the statement that for all real numbers, for both addition and multiplication, the inverse of a number's inverse is itself. For addition we can apply the property that $x + I_+(x) = 0$ with $x = I_+(a)$ to obtain \begin{gather*}
I_+(a) + I_+\big(I_+(a)\big) = 0
\end{gather*}
Applying commutativity of addition (RNFA2) we can swap the sides of the addition and obtain \begin{gather*}
I_+\big(I_+(a)\big) + I_+(a) = 0
\end{gather*}

As stated above, this matches the form of subtraction, $x + I_+(y) = x - y$, where $x = I_+\big(I_+(a)\big)$ and $y = a$. This means that we are considering \begin{gather*}
I_+(I_+(a)) - a = 0
\end{gather*}
But we had said earlier that subtraction is defined $x - y = z$ by being the $z$ that solves $z + y = x$, so this may be rewritten as \begin{gather*}
I_+(I_+(a)) = 0 + a.
\end{gather*}
Finally applying RNFA3 to eliminate zeroes, we obtain $I_+(I_+(a)) = a$. The process of the proof is the same for multiplication, except that at the end we apply RNFA7 to eliminate $z_\times$, the one's. 

Part b is significantly easier, as it is basically tautological. Recall the definition of division as above, that is, $x/y = w$ has $w$ that solves $wy = x$, presuming that $y \neq 0$. Set $x = 1 = z_\times$ and $y = a$; then $w a = z_\times$. But by RNFA8 this $w$ must be the unique multiplicative inverse of $a$, $w= I_\times(a)$. Rewriting the original division, we then have $1/a = I_\times(a)$.

For part c, we apply RNFA3 in reverse to turn $z_+$ into $z_+ + z_+$, adding a zero. Thus $z_+ a$ is also \begin{align*}
z_+ a &= (z_+ + z_+) a \\
&= z_+ a + z_+ a
\end{align*}
by distributivity (RNFA9). Subtracting $z_+(a)$ from both sides (or rather adding $I_+(z_+ a)$) we obtain via RNFA4 and RNFA3 \begin{align*}
(z_+ a) + I_+\big(z_+(a)\big) &= (z_+ a) + (z_+ a) + I_+\big(z_+(a)\big)  \\
z_+ &=  z_+ a 
\end{align*}
showing that zero multiplied by anything is zero.

Part d consists of proving $I_+(a) = I_+(z_\times)a$. Begin from reflexivity of equivalence, writing $I_+(a)/a = I_+(a)/a$, a number's additive inverse divided by itself. Set $w = I_+(a)/a$ and then add one to both sides, obtaining \begin{gather*}
w + 1 = \frac{I_+(a)}{a} + 1
\end{gather*}
Now by RNFA8, we replace $1 = a I_\times(a) = a/a$ and write \begin{gather*}
w + 1 = \frac{I_+(a)}{a} + \frac{a}{a}
\end{gather*}
These divisions by $a$ are of course shorthands for multiplying by $I_\times(a)$, so we may apply distributivity (RNFA9) and rewrite the right hand side to $\frac{1}{a}(I_+(a) + a)$. \begin{gather*}
w + 1 = \frac{I_+(a) + a}{a}
\end{gather*}
But now by RNFA4, the top of the fraction must be zero since we are adding a number with its additive inverse. This also means that the entire right hand side is zero by part c of the lemma, since anything ($I_\times(a)$ in this case) multiplied by zero is zero. So that means \begin{gather*}
w + 1 = z_+
\end{gather*}
implying that $w$ is the unique additive inverse to $1 = z_\times$ by RNFA8. Thus $w = I_+(z_\times)$ is the value we had in $w = I_+(a)/a$. Displaying this division in its alternate form with $w = I_+(z_\times)$ substituted, this is finally \begin{gather*}
I_+(a) = I_+(z_\times) a
\end{gather*}
\end{my proof}

At this stage, we have effectively demonstrated what the inverse operation is for addition and multiplication, specifically that $I_\times(a) = 1/a$ and $I_+(a) = - a$. We can now, with complete certainty, take these notations as proven to be consistent within our number system. As we prove more such statements as these, statements which we might normally take to be obvious, our list of rewrite rules will grow until they begin to form something like an intuition, or at least a feel for the game we have created for ourselves.

Our next stop in making this game easier for ourselves will be to fill out some of our intuitions about how ordering operations work. As you may have seen above, we take as axioms that orderings obey translations and dilations (i.e. they remain true under additions and multiplications) even though we did not take this as an axiom for equivalence (where we had to derive these rewrite rules as in lemma \ref{lem:RealNumsAlgebraRewrites}). This is in part because we've never seen a formal ordering before, and we are in some sense defining simultaneously what an ordering \emph{does}.

In fact, we have not said anything at all about what it \emph{means} to write $a < b$, or any of these operations so far within a formal context. Of course we know the symbol $<$ to mean \textbf{less than} but the point in some sense is that its meaning here will appear not from what we name it but from what properties it has. Only having chosen those properties well, as is the case with these axioms, will we know for sure that this symbol and its properties reflects the intuition we wish it to match with.

\begin{label proposition}[Ordering Rules for Negatives]{BasicROrderProperties}
Let $a,b,c,d \in \reals$ and let $a < b$.
\begin{enumerate}
\item Then we may write $- b < -a$, reversing the order on the number's negatives.
\item If $c < 0$ then we have $b c < a c$ (by comparison to RNOA4 which required $0 < c$ and implied $a c < b c$).
\item If we have $c < d$ then we have $a + c < b + d$.
\end{enumerate}
\end{label proposition}
\begin{my proof}{mo}
Begin with the hypothesis $a < b$. By RNOA3 we may translate by the value $-a - b$.
\begin{gather*}
a + (-a - b) < b + ( -a - b)
\end{gather*}
From there, it will be necessary to apply associativity of addition (RNFA1) and commutativity of addition to rearrange terms (RNFA2),\begin{align*}
a + (-a - b) &< b + ( -a - b) \\
(a - a) - b &< b + (- b -a)  \\
0 + (- b) &< (b - b) - a \\
&< 0 + (- a)
\end{align*} followed finally by RNFA3 to eliminate zeros. \begin{gather*}
-b < -a.
\end{gather*}
For part b we will need to use part a and proposition \ref{pro:RealNumInverses} in the following manner. By part $a$, we have that $c < 0$ implies $0 < -c$ (that is, when $c$ is a negative number), which means $-c$ satisfies the requirement for RNOA4 to rewrite $a < b$ to \begin{gather*}
a (-c) < b(-c).
\end{gather*}
Applying proposition \ref{pro:RealNumInverses}, we know that these negatives (or rather additive inverses) are simply numbers multiplied by $-1$, so applying commutativity of multiplication (RNFA6) we have \begin{align*}
a (-1) c &< b (-1) c \\
(-1) a c &< (-1) b c \\
-a c &< - b c
\end{align*}
Applying part a of proposition \ref{pro:RealNumInverses}, $I_+(I_+(a)) = a$ or in this case $-(-a) = a$, together with part a of this proposition, we use $-a c < - b c$ to imply \begin{align*}
-(- b c) &< - (-a c) \\
b c &< a c
\end{align*}
as desired.

Part $c$ follows by applying translations and transitivity (RNOA3 and then RNOA2). That is, add $c$ to both sides of $a < b$ to get $a + c < b + c$. Now add $b$ to both sides of $c < d$ to obtain $b + c < b + d$. Now the right hand side of $a + c < b + c$ is the same as the left hand side of $b + c < b + d$, so by transitivity we have \begin{gather*}
a + c < b + c < b + d
\end{gather*}
implying \begin{gather*}
a + c < b + d
\end{gather*}
and we are done.
\end{my proof}

From this point on, we will begin taking some of these symbolic properties increasingly more for granted. For instance, we will slowly stop mentioning when we apply commutativity of addition or mulitplication (RNFA2 or RNFA6) or associativity (RNFA1 or RNFA5) when we reorder terms in sums or products. Nonetheless, the fact that we understand that we can do these reorderings is always strictly because they were written here. Because we \emph{have the property} that these rewrites are valid.

\subsection{The Archimedean Property}

Now that we have seen some examples of demonstrating things that we already intuit to be true using strict axiomatic rewrites, we are in a position to demonstrate some things we might not know with equal certainty. In particular, we are ready to demonstrate that real numbers do not contain infinitessimals.

The concept of an infinitessimal in popular understanding is a confused one despite its ubiquity. For people in physics or certain less formal branches of applied mathematics such as engineering or financial mathematics, an infinitessimal is the $dx$ in a derivative $\frac{df}{dx}$ or in an integral $\int f dx$. However most people without such a background encounter the concept as the idea of a number 0.9999 with infinite repeating 9s; it is common once such a quantity is proposed to then debate whether that number is equal to 1 or is its own number. Importantly, the number is not 0.999 or 0.999999 but an infinite number of unwritten 9s, and so the whole point of the number is that you are in some sense unable to pin it down as anything but \squote{closer but not equal to one}, since more 9s must be written. In some sense the concept is a modern instantiation of Zeno's paradox, of the distance divided into infinite segments, first 0.9 then 0.09 then 0.009, which can never reach their target of 1.

Why infinitessimals might be real numbers at all is largely a confusion born of the tricks used in physics courses and earlier studies of calculus, since looking at derivatives written $\frac{df}{dx}$ and thinking that $df$ and $dx$ are themselves values can sometimes yield correct and valuable results. In fact there is a sense in which it is true that they are \emph{values}, or at least, that there are formalisms within which we can speak of $df$ and $dx$ as being mathematical objects with distinct algebraic rules similar to that of a number. But for the sake of a discussion of real numbers, it is important to emphasize that these objects, whatever they may be, are \emph{not} real numbers. Real numbers obey something called the \emph{Archimedian property} which forbids the notion of infinitessimal numbers.

There are many ways to express the Archimedian property, each focusing on various aspects of it. Here, we will write the Archimidean property specifically as the property that there are no such thing as infinitessimal reals, and \emph{because} there are no infinitessimal reals, any two real numbers are non-equal if and only if have some number between them. Expressing this statement poses a difficulty however; if there \emph{were} infinitessimal real numbers, then they would of course lay on the number line just as any other number and we would have difficulty distinguishing them from other non-infinitessimal real numbers. So instead, in this context, we will think of the idea of an infinitessimal number as one that is smaller than all \emph{positive rational numbers}, that is, all $q \in \rationals$ which are $q > 0$, the set of positive rational numbers $\rationals^+$. 

\begin{label theorem}[Archimedian Property]{RealArchimedianProperty}
There are no elements $h \in \reals$ which are $h > 0$ and also $h < q$ for all positive rational numbers $q \in \rationals^+ \subset \reals$.
\end{label theorem}

\begin{my proof}[Proof. $\hspace{0.5em}$ (Adapted from the proof on Wikipedia)]{mo}
We proceed with a proof by contradiction. Accordingly, assume for the sake of contradiction that there did exist a real number $h \in \reals$ which were both $h > 0$ and also $h < q$ for all $q \in \rationals^+$. Then there would exist a set of all infinitessimal numbers \begin{gather*}
Z = \big\{ h\in \reals \hspace{0.2em}\big| \hspace{0.2em} \forall q\in \rationals^+, (h < q) \wedge (h > 0) \big\}
\end{gather*}
and since we are assuming such an infinitessimal real number exists, we are insisting that $Z \neq \emptyset$, that this set of all infinitessimals is non-empty. By the axiom of completeness for $\reals$, since the set has any positive rational number as an upper bound and the set is non-empty by hypothesis, it must have a least upper bound $c = \sup(Z)$.

Consider now that $c$ must dominate all would-be infinitessimals, that is, $z \le c$ for all $z \in Z$, and that any number larger than $c$ must not be in $Z$ since $c$ \emph{bounds} $Z$. Then we can say with certainty that $2c$ is \emph{not} an infinitessimal because $c < 2c$ (which we deduce by adding $c$ to both sides of $0 < c$). Since $2c \notin Z$ and $2c > 0$, in order to have avoided being a member of $Z$ there must have existed some $k \in \rationals^+$ which is $k \le 2c$.

On the other side, $c / 2$ is small enough that it should be an infinitessimal, since $c$ is the \emph{least} (smallest) upper bound of $Z$, so whether or not $c$ itself is in $Z$, anything smaller than $c$ but greater than zero is less than all $q \in Q^+$ and thus must be in $Z$. Since $c$ is a least upper bound of $Z$ and $Z$ is defined by its elements being greater than zero, we know that any $x$ which satisfies $0 < x < c$ must be $x \in Z$. Moreover this means that any $x$ which satisfies $0< c/4 < x < c/2 < c$ is an infinitessimal.

Now, there must exist some $k \in \rationals^+$ which is $c \le k \le 2c$ or else any other number between $c$ and $2c$, say $\frac32 c$, would be an infinitessimal thus violating $c$'s \emph{least} upper bound property. But since such a rational number exists, we may simply divide the transitive inequality by four, obtaining $c/4 < k/4 < c/2$. As discussed earlier, any number satisfying that property must be infinitessimal, but at the same time, $k/4$ is a rational number divided by another rational number and thus a rational number itself. Since it is smaller than $c/2$, its existence implies that $c/2$ was not an infinitessimal, but that would also mean that $c/2$ bounds the infinitessimals, making it a lesser bound than $c$ which was supposed to be the least upper bound.

This provides the contradiction which implies $Z$ must be empty.
\end{my proof}

As a corollary, this property may be thought of as saying that numbers such as $0.999$ repeating are equal to the number they infinitely approximate. That is, if infinitessimals do not exist in the reals, then there is also no notion of a number being infinitessimally larger or infinitessimally smaller than another; recall the property of trichotomoy for orderings (RNOA1) which says that two numbers $a,b$ are either $a < b$, $a = b$ or $a > b$, so a number such as $0.999$ repeating which we suppose is larger than all other numbers we can \emph{specifically point to} less than one ($0.998$, $0.9999453$, etc.) must only be equal to one. It seems obvious to say then that when the Archimedean property is true, as stated earlier, two real numbers are non-equal if and only if there exists a number between them. Superficially, we could already say that this was $a \neq b$ if $a \neq \frac{a + b}{2} \neq b$ with $(a+b)/2$ their average between them when they are not equal; but now we can be certain that no consequence of real numbers mean that there would be a quantity which is \emph{hard to refer to} strange way.

We will later substantiate the meaning of infinitessimals in an informal sense, mostly as a tool for visualization wrapped up in significant algebraic (or, context dependently, analytic) abstractions, but these tools will never be \dquote{real numbers}. No matter how much abstraction we build up, if we are ever asked to find \emph{a number} which is somehow smaller than any other thing but greater than zero, we will say confidently that it does not exist.

\subsection{The Triangle Inequality}

We have one last serious property of the real numbers to prove, known as the \emph{triangle inequality}. This inequality in some sense is our first taste of the flavor of real analysis as a discipline; indeed we will use this inequality heavily despite its seemingly inane symbolic statement.

The triangle inequality is born of the obvious fact that one cannot draw a triangle with any one side greater than the length of the other two. This property is obvious in the setting of euclidean geometry (no doubt, you can demonstrate right now with a piece of paper) but as we discuss more abstract spaces, expecting the triangle inequality to hold will constitute a very particular choice about exactly how abstract a notion of space we wish to describe. For instance, should a \emph{space of functions} with a notion of distance satisfy the triangle inequality with that notion of distance? We will later say that the answer is generally yes. Should a space of possible outcomes, an \emph{event space}, which we measure in probabilities, have a triangle inequality? Generally we say the answer is no in that case. But the kinds of things an abstract definition of \emph{space} can describe are downstream of the properties we expect of that space, and expecting or not expecting the triangle inequality will define what kind of space it is.

In this case, we will be demonstrating the not-so-obvious fact that the triangle inequality, the inability to draw a three sided shape with one side greater than the sum of the other two, holds not just in two or more dimensions, but even on only one dimension. Yes, even on merely the number \emph{line}, we have the triangle inequality, and we can prove it as a natural consequence of the real number axioms.

But to do this, we will first need the \emph{absolute value} operation. You may know this operation as the the one that leaves positive values the same but makes negative values become positive; in fact that will be our definition today, but I must foreshadow that despite its simplicity, the full scope of properties the absolute value has on other spaces will, in time, prove fascinating on its own.

\begin{label definition}[Absolute Value]{RealAbsoluteValue}
Given $a \in \reals$, denote by $|a|$ the \textbf{absolute value} of $a$, that is, the number of equal magnitude to $a$ which is non-negative. Formally, if $0 \le a$ then $|a| = a$, but if $a < 0$ then $|a| = -a$ in order to make it positive. \begin{gather*}
|x| = \left\{ \begin{matrix}
	-x, & x < 0\\
	x, & x \ge 0\\
\end{matrix}
 \right.
\end{gather*}
As a simple consequence, $|-a| = |a|$ and $|k||a| = |ka|$ for all $k \in \reals$ and $|ka| = k |a|$ for all $k \ge 0$.
\end{label definition}

\begin{label theorem}[Triangle Inequality]{RTriangleInequality}
Any three $a,b,c \in \reals$ satisfy the property \begin{gather*}
|a - c| \le |a - b| + |b-c|.
\end{gather*}
called the \textbf{triangle inequality} in $\reals$.
\end{label theorem}

This symbolic statement can then be read as the property we mentioned earlier; we read each $|a-c|$, $|a-b|$ and $|b-c|$ as the distances between points, since in $\reals$ distances between numbers are merely their positive differences. Then it is literally that the distance between any two points is less than or equal to the sum of the other two distances.

\begin{my proof}{mo}
This proof proceeds by brute force case analysis. There are six ways to order the three values, i.e. each case of ordering is something like $a \le b \le c$ or $b \le c \le a$ or something like that (this is applying RNOA1, since each pair of numbers must be either less than or equal to each other or greater than or equal to each other). Given that we are only concerned with the magnitude of their \emph{differences} however, the proof where we assume $a \le b \le c$ is also actually a proof for the case where $c \le b \le a$, since we could change $a$ to $-a$, $b$ to $-b$ and $c$ to $-c$, and each term, each difference $|a - c|$ would become \begin{align*}
|a - c| \mapsto |(-a) - (-c)| &= |-a + c| \\
&= |c - a| \\
&= |a - c|
\end{align*}
and so our six cases become only three that we care about where the triangle inequality is concerned. These are cases are labelled (1), (2) and (3) respectively. \begin{gather*}
(1) \hspace{1em} a \le b \le c \\
(2) \hspace{1em} b \le a \le c \\
(3) \hspace{1em} a \le c \le b
\end{gather*}

Let's start with case (1). In this case, $a-b$, $b - c$ and $a - c$ are all negative, so we may apply the appropriate sign changes to compute the absolute values in the triangle inequality we wish to prove as follows. \begin{gather*}
c - a \le (b - a) + (c - b)
\end{gather*}
We can obtain this easily by starting with reflexivity of equality $c - a = c - a$ stated as $c - a \le c - a$ and then deduce this statement, but in this case it will be more obvious if we complete the proof by \emph{rewriting on the goal}. That is, if we can show that the thing we aim to prove can be rewritten as a fact which we know to be trivially true, then the proof is completed. We have already begun this process by deducing that when $a \le b \le c$, the triangle inequality is written as above. We continue this process by merely simplifying the statement. \begin{align*}
c - a &\le (b - a) + (c - b) \\
&\le b - b + c - a \\
&\le 0 + c - a \\
&\le c - a
\end{align*}
This of course obtains the same statement we noted earlier was true by reflexivity of equality. We could of course do these steps in reverse, proceeding from $c - a \le c - a$, adding $b - b$ to the right hand side using proposition \ref{pro:BasicROrderProperties}.c (with $\le$ instead of $<$), but the fact that we could do these steps in reverse is exactly the reason we do not have to.

Concluding case (1), we study case (2) by applying a similar method of computing the absolute values when $b \le a \le c$. \begin{align*}
c - a &\le (a - b) + (c - b) \\
&\le a + b - 2b
\end{align*}
Now to both sides, add $b - c$ (i.e. apply RNOA3) to obtain \begin{align*}
c-a (b-c) &\le a + c - 2b + (b-c) \\
b - a & \le a - b
\end{align*}
This is then the statement we need to prove. Since $b \le a$ as in $b \le a \le c$, we have $b - a\le 0$ by subtracting $a$ from both sides of $b \le a$, and at the same time we could subtract $b$ from both sides of $b \le a$ and obtain $0 \le a- b$. By transitivity (RNOA2) we have \begin{gather*}
b - a \le 0 \le a - b \\
b - a \le a - b
\end{gather*}
which is what we wanted to show. Thus case (2) is covered.

Case (3) will proceed similarly as in case (2). Our goal of the triangle inequality, when $a \le c \le b$, is read \begin{align*}
c- a &\le (b-a) + (b - c) \\
c - a &\le 2b - a - c.
\end{align*}
Adding $a - c$ to both sides we obtain \begin{gather*}
c-a + (a - c) \le 2b - a - c + (a-c) \\
0 \le 2b - 2c.
\end{gather*}
Since $c \le b$ as in $a \le c \le b$ of case (3), we know by RNOA4 that $2 c \le 2 b$, and subtracting $2c$ from both sides, that $0 \le 2b - 2c$. But this is what we wanted to show, the case (3) form of the triangle inequality.

Then we have shown all three relevant cases for the triangle inequality on $\reals$ and know it to be true in general.
\end{my proof}

\subsection{Section Appendix: Some Loose Ends}

The above proofs hopefully serve to show that one can prove statements that might seem so simple as to be tautological so long as we have a strong axiomatic basis. However, as you can see, this can lead to quite verbose proofs. From here on, going into the rest of the chapter and chapters beyond it, we will be a little more terse unless we are discussing a brand new concept, with the understanding that we know a bit about how to work with real numbers.

Accordingly, we will largely mostly forget the axiomatic description of the reals except when it is necessary to disentangle a specific property related to numbers themselves. We will however need to bring some things with us foward, such as the triangle inequality, and we must pay attention in future for when a mathematical construction has many or most of the axioms of the real numbers, since they may share properties. It will also serve us well to state some earlier mentioned concepts in a self contained form to establish notational rules and strict definitions.

Here we will begin to establish a formal pattern that most sections will come with a section appendix, a collection of statements, proofs, or intuitive descriptions which are either tangential to the direction of our exposition or do not fit neatly within it. In general, it is recommended that treat section appendices as either references or as almost standalone discussions. In fact it is somewhat optional to read a section appendix at the moment you encounter it, but almost all section appendices will become relevant later, and are written so that you \emph{can} understand them when you encounter them, even if their true importance will only be revealed later. Nonetheless, I hope that you enter the following section trying to follow where the thread left off just before the appendix began.

\begin{label definition}[Upper and Lower Bounds]{RUpperLowerBounds}
Let $A \subset \reals$ be a set of real numbers. We say that $b$ is a \textbf{upper bound} of $A$ (respectively a \textbf{lower bound}) if for all $a \in A$, $b$ satisfies $a < b$ (respectively $b < a$ for lower bounds).

If $A$ has both an upper bound and a lower bound, we say that $A$ is \textbf{bounded}.
\end{label definition}

\begin{label definition}[Supremum and Infimum of a Set]{RSupremumInfimum}
Let $A \subset \reals$ be a set of real numbers. Denote by $\sup(A)$ the \textbf{supremum} of $A$, meaning a value $\sup(A) \in \reals$ which is an upper bound for $A$, but is also $\sup(A) \le b$ for all $b \in \reals$ which are upper bounds for $A$. We also have the \textbf{infimum} denoted $\inf(A)$ which is the \emph{greatest lower bound} satisfying $\inf(A) > b$ for all $b$ which are lower bounds of $A$, or equivalently $\inf(A) = -\sup(\{-x | x \in A\})$.

The supremum and infimum can be thought of as analogous to the \textbf{maximum} and \textbf{minimum} of a set, but where it may be impossible to specify a largest or smallest value which is itself included in the set (say because a set does not include its endpoints). When it is possible, the supremum is equal to the maximum (and the infimum to the minimum), but when it is not the supremum will select the excluded endpoint, thus sometimes $\sup(A) \notin A$.

%Sometimes we will write the supremum as $\sup_{x \in A}(f(x))$ to mean the supremum of the image $\sup(f(A))$, but we may also sometimes write $\text{argsup}_{x\in A}(f(x))$ to mean the specific $x$ which makes $f(x)$ the supremum of $f(A)$. Analogous notations exist for $\text{argmin}$, $\text{argmax}$, and $\text{arginf}$, but they are not guarenteed to produce only a single value if $f$ is not injective; moreover $\text{argsup}$ and $\textbf{arginf}$ may produce values which are themselves outside the set.
\end{label definition}

Finally, we include one last property of functions with respect to orderings which will be valuable in the next section. That is, we showed under what circumstances $x = y$ can be rewritten to $f(x)=f(y)$ or back (namely when $f$ is injective), but we did not show the corresponding property for orders. That is in part because we must speak about a new property of functions when they go from ordered sets to ordered sets. We must discuss \emph{monotonicity}.

\begin{label definition}[Monotonic Functions]{MonotonicFunction}
Let $f \colon \reals \to \reals$. If $f$ has the property that for all $x,y \in \reals$ $x < y$ implies $f(x) < f(y)$ then we say that $f$ is a \textbf{strictly monotonic increasing} function, that is, it is a function for which a larger input $y$ will always yield a larger output $f(y)$ than the output for the previous input $f(x)$. There is also the corresponding property of \textbf{strictly monotonic decreasing} function for which $x < y$ implies $f(y) < f(x)$.

When instead we have that $x < y$ implies $f(x) \le f(y)$, we say that $f$ is a \textbf{monotonic increasing} function, or a \textbf{monotonic non-decreasing} function, signifying that larger inputs may not always lead to larger outputs, but that the outputs are at least as big as all inputs before and no smaller. Correspondingly, a function for which $x < y$ implies $f(y) \le f(x)$ is a \textbf{monotonic decreasing} or \textbf{monotonic non-increasing} function. 
\end{label definition}

In the context of this, we can see that addition by a constant $x \mapsto x + a$ is a strictly monotonic increasing function, since $x < y$ has $x + a < x + y$ by RNOA3 and similarly $x \mapsto xa$ is monotonic increasing when $0 < a$ by RNOA4.

\begin{label corollary}[Composition of Monotonic Functions]{CompositionOfMonotonicFunctions}
Let $f,g\colon \reals \to \reals$ be functions.\begin{itemize}
\item if $f$ and $g$ are monotonic increasing, then $g \circ f$ is also monotonic increasing
\item if $f$ and $g$ are monotonic decreasing, then $g \circ f$ is monotonic \emph{increasing} since the ordering is reversed twice.
\end{itemize}
\end{label corollary}

\begin{label corollary}[Some Basic Monotonic functions]{ListOfBasicMonotonicFunctions}
I encourage you to go to \href{https://www.desmos.com/calculator}{desmos.com/calculator} or anywhere else you like to graph functions and graph these functions yourself to see that they are monotonic in the way described. When we speak of conditional monotonicity, we mean that $x < y$ implies $f(x) < f(y)$ or $f(x) > f(y)$ respectively when both $x$ and $y$ satisfy the condition.
\begin{itemize}
\item $x \mapsto x$ is strictly montonic increasing
\item $x \mapsto -x$ is strictly montonic decreasing
\item $x \mapsto x^3$ is strictly monotonic increasing
\item $x \mapsto e^x$ is strictly monotonic increasing
\item $x \mapsto \sqrt{x}$ is strictly monotonic increasing when valid, i.e. on $x \ge 0$
\item $x \mapsto \log x$ is strictly monotonic increasing when valid, i.e. on $x > 0$
\item $x \mapsto x^2$ is strictly monotonic increasing when $x > 0$ and strictly monotonic decreasing when $x < 0$
\item $x \mapsto 1/x$ is strictly monotonic decreasing on $x < 0$ and on $x>0$ separately but not together due to the discontinuity of one divided by zero
\end{itemize}
\end{label corollary}

Finally, some facts should be elaborated about absolute values before we move forward. This is by no means the rich properties they hold which we must discuss much later, but it will save us a great deal of time explaining why these properties are true on a case by case basis later.

\begin{label lemma}[Absolute Value Properties]{RAbsoluteValueProperties}
It will prove valuable to understand some basic properties of absolute values. Let $a,k\in \reals$. Then the following are true: \begin{enumerate}
\item $|-a| = |a|$
\item $|ka| = |k| |a|$
\item if $k \ge 0$ then $|ka| = k |a|$
\item $x \mapsto |x|$ is monotonic increasing when $x \ge 0$ and monotonic decreasing on $x \le 0$.
\item $|a| \le k$ is an equivalent statement to $-k \le a \le k$
\end{enumerate}
\end{label lemma}
\begin{my proof}{m}
\begin{enumerate}
\item Consider the two possibilities: if $a$ is positive, then $|a| = a$, and since $-a$ is negative, we get $|-a| = -(-a) = a$. Consequently it is clear that $|-a| = a = |a|$. A similar argument follows if $a$ is negative, since $|a| = -a$, and $-a$ is positive, making $|-a| = -a$. Once again we get $|-a| = -a = |a|$. Although in the first case they are both $a$ and in the second case they are both $-a$, ultimately $|-a| = |a|$ remains true either way.

\item This is a more general case of the latter. There are four relevant cases, $k \ge 0$ and $a \ge 0$, $k \le 0$ and $a \ge 0$, $k \ge 0$ and $a \le 0$, and finally $k \le 0$ and $a \le 0$. In each of these cases, the first thing to notice is whether they are both positive or both negative since this will make their product positive, or rather if one is positive and one is negative in which case their product is negative. Thus we have \begin{gather*}
(k \ge 0) \wedge (a \ge 0) \implies |ka| = ka \\
(k \le 0) \wedge (a \ge 0) \implies |ka| = -ka \\
(k \ge 0) \wedge (a \le 0) \implies |ka| = -ka \\
(k \le 0) \wedge (a \le 0) \implies |ka| = ka
\end{gather*}
and on the individual factors we have \begin{gather*}
(k \ge 0) \wedge (a \ge 0) \implies (|k| = k) \wedge (|a| = a)  \\
(k \le 0) \wedge (a \ge 0) \implies (|k| = - k) \wedge (|a| = a)  \\
(k \ge 0) \wedge (a \le 0) \implies (|k| = k) \wedge (|a| = -a)  \\
(k \le 0) \wedge (a \le 0) \implies (|k| = -k) \wedge (|a| = -a) 
\end{gather*}
but we see that $(-k)(-a) = ka$ and that $(-k)a = k (-a) = -k a$. So we may write \begin{gather*}
(k \ge 0) \wedge (a \ge 0) \implies |ka| = ka = |k||a| \\
(k \le 0) \wedge (a \ge 0) \implies |ka| = -ka = |k||a|\\
(k \ge 0) \wedge (a \le 0) \implies |ka| = -ka = |k||a|\\
(k \le 0) \wedge (a \le 0) \implies |ka| = ka = |k||a|
\end{gather*}
and thus in every case we obtain $|ka| = |k||a|$.

\item This is clearly just one of the cases of the previous proof and is included for emphasis only.

\item Let $x,y \in \reals$. If $0 < x < y$ then $x$ and $y$ are positive numbers, meaning $|x| = x$ and $|y| = y$, so it is clear that $x < y$ implies $|x| < |y|$ and $x \mapsto |x|$ is behaving as strictly monotonic increasing. If $x < y < 0$, then $x$ and $y$ are negative numbers, and so $|x| = -x$ and $|y| = -y$. We can take our existing statement in this case $x < y$ and multiply both sides by $-1$ (this applies proposition \ref{pro:BasicROrderProperties}.b with $c=-1$) to obtain $-x > -y$ which is then rewritten $|x| > |y|$, flipping the sign as a strictly monotonic decreasing function does.

\item Consider that $|a|$ is positive regardless of whether $a$ is positive, and since $k \ge |a|$, it must be that $k$ is positive. This also means that if $a$ is positive, $k \ge |a| = a$ but if $a$ is negative, as a negative number smaller than zero, $k \ge a$ anyway. So we have that $k \ge |a|$ implies $k \ge a$.

On the other side, if $|a| = -a$ then $-a$ is a positive number, and we may write $k \ge |a| = -a$. Multiplying both sides of this by $-1$, we obtain $-k \le a$ when $a$ is negative. When $a$ is positive, $-k \le a$ remains true anyway, since $k$ is less than zero and $a$ is more than zero.

Together, we have $-k \le a$ and $a \le k$ regardless of the positivity/negativity of $a$, completing the proof in one direction.

In the other direction, assume it is known that $-k \le a \le k$. Once again this implies that $k$ is positive, since by transitivity we have $-k \le k$. If $a$ is positive then by $a \le k$, we know that $|a| \le k$. If $a$ is negative then by $-k \le a$ we can multiply the inequality by $-1$ to obtain $k \ge -a$ and since $|a| = -a$ in this case, it is $k \ge |a|$ as well. Once again, in either case we obtain $k \ge |a|$.
\end{enumerate}
\end{my proof}

\end{document}